{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'0.20.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取登录数据\n",
    "loginData=pd.read_csv('input/t_login.csv',dtype={'log_id':str,'id':str,'device':str,'log_from':str,'ip':str,'city':str,'result':str,'type':str})\n",
    "loginDataTest=pd.read_csv('input/t_login_test.csv',dtype={'log_id':str,'id':str,'device':str,'log_from':str,'ip':str,'city':str,'result':str,'type':str})\n",
    "loginData=loginData.append(loginDataTest)\n",
    "loginData['time']=pd.to_datetime(loginData['time'])\n",
    "######重排索引，不然后续的根据索引来连接会出错####\n",
    "loginData=loginData.reset_index(drop=True)\n",
    "del loginDataTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取交易数据\n",
    "tradeData=pd.read_csv(\"input/trade_2_login.csv\",dtype={'id':str,'login_id':str})\n",
    "tradeData.rename(columns={'login_id':'log_id'},inplace=True)\n",
    "tradeData['time']=pd.to_datetime(tradeData['time'])\n",
    "\n",
    "tradeTestData=pd.read_csv(\"input/t_trade_test_2_login.csv\",dtype={'id':str,'login_id':str})\n",
    "tradeTestData.rename(columns={'login_id':'log_id'},inplace=True)\n",
    "tradeTestData['time']=pd.to_datetime(tradeTestData['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到用户id，并以id为index用于后续好添加用户相关行为\n",
    "def getUserIdData():\n",
    "    idList=loginData['id'].unique()\n",
    "    idData=pd.DataFrame({'id':idList},index=idList)\n",
    "    return idData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对登录数据的字段组进行聚合处理\n",
    "def  aggLoginDataById(userData,loginData,columns,aggFunNames):\n",
    "    if isinstance(columns,(str)):\n",
    "        columns=[columns]\n",
    "    if isinstance(aggFunNames,(str)):\n",
    "        aggFunNames=[aggFunNames]\n",
    "    id_cols=columns#.copy()\n",
    "    id_cols.append('id')\n",
    "    # print(id_cols)\n",
    "    t=loginData[id_cols].groupby(loginData['id'])[columns].agg(aggFunNames)\n",
    "    userData=pd.concat([userData, t], axis=1)\n",
    "    return userData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#登录的时间的处理\n",
    "def loginDataTimeInit(loginData):\n",
    "#     loginData['ts']=loginData['time']#.dt.second\n",
    "#     print(loginData.head(2))\n",
    "    t=loginData[['id','time']].sort_values(by='time').groupby('id')['time'].diff()\n",
    "    loginData['login_diff_day']=t.dt.days\n",
    "    loginData['login_diff_seconds']=t.dt.seconds\n",
    "    return loginData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对登录数据的处理\n",
    "def loginDataInit(loginData):\n",
    "    loginData=loginData.copy()\n",
    "    userData=getUserIdData()\n",
    "    userData=aggLoginDataById(userData,loginData,['device','log_from','city','result','type'],'nunique')\n",
    "    userData=aggLoginDataById(userData,loginData,'timelong',['min','max','std','var','mean','skew'])\n",
    "    loginData=loginDataTimeInit(loginData)\n",
    "    userData=aggLoginDataById(userData,loginData,['login_diff_day','login_diff_seconds'],['min','max','std','var','mean','skew','mad'])\n",
    "#     print(userData.head(2))\n",
    "    loginData=pd.merge(loginData,userData,on='id',how='inner')\n",
    "    del loginData['device'],loginData['log_from'],loginData['ip'],loginData['city']\n",
    "    del loginData['result'],loginData['timestamp'],loginData['type']\n",
    "    return loginData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对交易数据的处理\n",
    "def tradeDataInit(tradeData):\n",
    "    tradeData=tradeData.copy()\n",
    "    t=tradeData[['id','time']].sort_values(by='time').groupby('id')['time'].diff()\n",
    "    tradeData['trade_diff_time']=t.dt.seconds\n",
    "    return tradeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对登录和交易的融合的数据的处理，返回x,y\n",
    "def allDataInit(loginData,tradeData):\n",
    "    allData=pd.merge(tradeData,loginData,on='log_id',how='inner')\n",
    "    del allData['log_id'],allData['id_x'],allData['id_y']\n",
    "    del allData['time_x'],allData['time_y']\n",
    "    allData.info()\n",
    "#     del allData['is_sec'],allData['type'],allData['log_from'],allData['result'],allData['city']    \n",
    "    x=allData.iloc[:,2:].values\n",
    "    y=allData['is_risk'].values\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对登录和交易的融合的数据的处理，返回x,y\n",
    "def allDataTestInit(loginData,tradeData):\n",
    "    allData=pd.merge(tradeData,loginData,on='log_id',how='inner')    \n",
    "    del allData['log_id'],allData['id_x'],allData['id_y']\n",
    "    del allData['time_x'],allData['time_y']\n",
    "    allData.info()    \n",
    "    x=allData.iloc[:,1:].values\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "#评估函数\n",
    "def rocJdScore(*args):\n",
    "    from sklearn import metrics\n",
    "    return metrics.make_scorer(fbeta_score,beta=0.1, greater_is_better=True)(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成训练用的pipline\n",
    "def getPipe():\n",
    "    # 下面，我要用逻辑回归拟合模型，并用标准化和PCA（30维->2维）对数据预处理，用Pipeline类把这些过程链接在一起\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    import xgboost as xgb\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "    #xgb的配置\n",
    "    xgbFier = XGBClassifier(\n",
    "             learning_rate =0.3,\n",
    "             n_estimators=1000,\n",
    "             max_depth=5,\n",
    "             min_child_weight=1,\n",
    "             gamma=0,\n",
    "             subsample=0.8,\n",
    "             colsample_bytree=0.8,\n",
    "             objective= 'binary:logistic',\n",
    "             nthread=2,\n",
    "             scale_pos_weight=1,\n",
    "             seed=27,\n",
    "             silent=0\n",
    "    )\n",
    "    # 用StandardScaler和PCA作为转换器，LogisticRegression作为评估器\n",
    "    estimators = [\n",
    "#         ('scl', StandardScaler()), \n",
    "#                   ('pca', PCA(n_components=2)), \n",
    "#                    ('rf', RandomForestClassifier(random_state=1,\n",
    "#                                                  max_depth= 50,\n",
    "#                                                  min_samples_leaf= 3,\n",
    "#                                                  min_samples_split= 10,\n",
    "#                                                  n_estimators= 20,\n",
    "#                                                 )),\n",
    "#                   ('dtc',DecisionTreeClassifier(criterion='entropy')),\n",
    "                                    ('xgb',xgbFier),\n",
    "#                   ('lr', LogisticRegression())\n",
    "                 ]\n",
    "    # estimators = [ ('clf', RandomForestClassifier(random_state=1))]\n",
    "    # Pipeline类接收一个包含元组的列表作为参数，每个元组的第一个值为任意的字符串标识符，\n",
    "    #比如：我们可以通过pipe_lr.named_steps['pca']来访问PCA组件;第二个值为scikit-learn的转换器或评估器\n",
    "    pipe_lr = Pipeline(estimators)\n",
    "    return pipe_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2e7196308ff5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m          \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "clf = XGBClassifier(\n",
    "         learning_rate =0.3,\n",
    "         n_estimators=1000,\n",
    "         max_depth=5,\n",
    "         min_child_weight=1,\n",
    "         gamma=0,\n",
    "         subsample=0.8,\n",
    "         colsample_bytree=0.8,\n",
    "         objective= 'binary:logistic',\n",
    "         nthread=2,\n",
    "         scale_pos_weight=1,\n",
    "         seed=27,\n",
    "         silent=0\n",
    ")\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 121200 entries, 0 to 121199\n",
      "Data columns (total 34 columns):\n",
      "rowkey                        121200 non-null int64\n",
      "is_risk                       121200 non-null int64\n",
      "trade_diff_time               98610 non-null float64\n",
      "timelong                      121200 non-null float64\n",
      "is_scan                       121200 non-null bool\n",
      "is_sec                        121200 non-null bool\n",
      "login_diff_day                106675 non-null float64\n",
      "login_diff_seconds            106675 non-null float64\n",
      "(device, nunique)             121200 non-null int64\n",
      "(log_from, nunique)           121200 non-null int64\n",
      "(city, nunique)               121200 non-null int64\n",
      "(result, nunique)             121200 non-null int64\n",
      "(type, nunique)               121200 non-null int64\n",
      "(id, nunique)                 121200 non-null int64\n",
      "(timelong, min)               121200 non-null float64\n",
      "(timelong, max)               121200 non-null float64\n",
      "(timelong, std)               117490 non-null float64\n",
      "(timelong, var)               117490 non-null float64\n",
      "(timelong, mean)              121200 non-null float64\n",
      "(timelong, skew)              112724 non-null float64\n",
      "(login_diff_day, min)         117490 non-null float64\n",
      "(login_diff_day, max)         117490 non-null float64\n",
      "(login_diff_day, std)         112724 non-null float64\n",
      "(login_diff_day, var)         112724 non-null float64\n",
      "(login_diff_day, mean)        117490 non-null float64\n",
      "(login_diff_day, skew)        106819 non-null float64\n",
      "(login_diff_day, mad)         117490 non-null float64\n",
      "(login_diff_seconds, min)     117490 non-null float64\n",
      "(login_diff_seconds, max)     117490 non-null float64\n",
      "(login_diff_seconds, std)     112724 non-null float64\n",
      "(login_diff_seconds, var)     112724 non-null float64\n",
      "(login_diff_seconds, mean)    117490 non-null float64\n",
      "(login_diff_seconds, skew)    106819 non-null float64\n",
      "(login_diff_seconds, mad)     117490 non-null float64\n",
      "dtypes: bool(2), float64(24), int64(8)\n",
      "memory usage: 30.7 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17752 entries, 0 to 17751\n",
      "Data columns (total 33 columns):\n",
      "rowkey                        17752 non-null int64\n",
      "trade_diff_time               10541 non-null float64\n",
      "timelong                      17752 non-null float64\n",
      "is_scan                       17752 non-null bool\n",
      "is_sec                        17752 non-null bool\n",
      "login_diff_day                17128 non-null float64\n",
      "login_diff_seconds            17128 non-null float64\n",
      "(device, nunique)             17752 non-null int64\n",
      "(log_from, nunique)           17752 non-null int64\n",
      "(city, nunique)               17752 non-null int64\n",
      "(result, nunique)             17752 non-null int64\n",
      "(type, nunique)               17752 non-null int64\n",
      "(id, nunique)                 17752 non-null int64\n",
      "(timelong, min)               17752 non-null float64\n",
      "(timelong, max)               17752 non-null float64\n",
      "(timelong, std)               17399 non-null float64\n",
      "(timelong, var)               17399 non-null float64\n",
      "(timelong, mean)              17752 non-null float64\n",
      "(timelong, skew)              16965 non-null float64\n",
      "(login_diff_day, min)         17399 non-null float64\n",
      "(login_diff_day, max)         17399 non-null float64\n",
      "(login_diff_day, std)         16965 non-null float64\n",
      "(login_diff_day, var)         16965 non-null float64\n",
      "(login_diff_day, mean)        17399 non-null float64\n",
      "(login_diff_day, skew)        16449 non-null float64\n",
      "(login_diff_day, mad)         17399 non-null float64\n",
      "(login_diff_seconds, min)     17399 non-null float64\n",
      "(login_diff_seconds, max)     17399 non-null float64\n",
      "(login_diff_seconds, std)     16965 non-null float64\n",
      "(login_diff_seconds, var)     16965 non-null float64\n",
      "(login_diff_seconds, mean)    17399 non-null float64\n",
      "(login_diff_seconds, skew)    16449 non-null float64\n",
      "(login_diff_seconds, mad)     17399 non-null float64\n",
      "dtypes: bool(2), float64(24), int64(7)\n",
      "memory usage: 4.4 MB\n"
     ]
    }
   ],
   "source": [
    "trainLoginData=loginDataInit(loginData)\n",
    "trainTradeData=tradeDataInit(tradeData)\n",
    "X_train,y_train=allDataInit(trainLoginData,trainTradeData)\n",
    "#testLoginData = loginDataInit()\n",
    "\n",
    "testTradeData = tradeDataInit(tradeTestData)\n",
    "X_test = allDataTestInit(trainLoginData, testTradeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe_lr=getPipe()\n",
    "pipe_lr.fit(X_train,y_train)\n",
    "predictions = pipe_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    17567\n",
      "1      308\n",
      "Name: prediction, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'prediction':predictions})\n",
    "result = pd.concat([tradeTestData['rowkey'],df],1)\n",
    "result = result.fillna(0)\n",
    "result['prediction'] = result['prediction'].astype(int)\n",
    "print result['prediction'].value_counts()\n",
    "#result.to_csv('output/result.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#k-fold交叉验证\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "#pipe_lr=getPipe()\n",
    "#trainLoginData=loginDataInit(loginData)\n",
    "#trainTradeData=tradeDataInit(tradeData)\n",
    "#X_train,y_train=allDataInit(trainLoginData,trainTradeData)\n",
    "#记录程序运行时间\n",
    "import time \n",
    "start_time = time.time()\n",
    "scores = cross_val_score(estimator=pipe_lr, X=X_train, y=y_train, cv=3, n_jobs=2,scoring=rocJdScore)\n",
    "print(scores)\n",
    "# #整体预测\n",
    "# X_train,y_train=getTrainData(isUndersample=False)\n",
    "# pipe_lr\n",
    "#输出运行时长\n",
    "cost_time = time.time()-start_time\n",
    "print(\"交叉验证 success!\",'\\n',\"cost time:\",cost_time,\"(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1b6e980326cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'#\\u5b66\\u4e60\\u66f2\\u7ebf\\nfrom sklearn.learning_curve import learning_curve\\n\\npipe_lr = getPipe()\\n\\ntrainLoginData=loginDataInit(loginData)\\ntrainTradeData=tradeDataInit(tradeData)\\nX_train,y_train=allDataInit(trainLoginData,trainTradeData)\\n# train_sizes\\u53c2\\u6570\\u6307\\u5b9a\\u7528\\u4e8e\\u751f\\u6210\\u5b66\\u4e60\\u66f2\\u7ebf\\u7684\\u8bad\\u7ec3\\u96c6\\u6570\\u91cf\\uff0c\\u5982\\u679c\\u662f\\u5206\\u6570\\u6307\\u7684\\u662f\\u76f8\\u5bf9\\u6570\\u91cf\\uff0c\\u6574\\u6570\\u6307\\u7684\\u662f\\u7edd\\u5bf9\\u6570\\u91cf\\ntrain_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr, X=X_train, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10), cv=3,\\n                                                        n_jobs=2,scoring=rocJdScore)\\nprint(\\'===\\'*10)\\ntrain_mean = np.mean(train_scores, axis=1)\\ntrain_std = np.std(train_scores, axis=1)\\ntest_mean = np.mean(test_scores, axis=1)\\ntest_std = np.std(test_scores, axis=1)\\n\\nplt.plot(train_sizes, train_mean, color=\\'blue\\', marker=\\'o\\', markersize=5, label=\\'training accuracy\\')\\nplt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color=\\'blue\\')\\nplt.plot(train_sizes, test_mean, color=\\'green\\', linestyle=\\'--\\', marker=\\'s\\', markersize=5, label=\\'validation accuracy\\')\\nplt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color=\\'green\\')\\nplt.grid()\\nplt.xlabel(\\'Number of training samples\\')\\nplt.ylabel(\\'Accuracy\\')\\nplt.legend(loc=\\'lower right\\')\\nplt.ylim([0.0, 1.0])\\nplt.savefig(\"curve.png\")\\nplt.show()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2116\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2117\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2118\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-61>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\IPython\\core\\magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\IPython\\core\\magics\\execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-310cdde04acd>\u001b[0m in \u001b[0;36mloginDataInit\u001b[1;34m(loginData)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mloginData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloginData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0muserData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetUserIdData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0muserData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggLoginDataById\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloginData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'device'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'log_from'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'city'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'nunique'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0muserData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggLoginDataById\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloginData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'timelong'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'std'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'var'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'skew'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mloginData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloginDataTimeInit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloginData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-4b05942f25ec>\u001b[0m in \u001b[0;36maggLoginDataById\u001b[1;34m(userData, loginData, columns, aggFunNames)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maggFunNames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0maggFunNames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maggFunNames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mid_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mid_cols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# print(id_cols)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#学习曲线\n",
    "from sklearn.learning_curve import learning_curve\n",
    "\n",
    "pipe_lr = getPipe()\n",
    "\n",
    "trainLoginData=loginDataInit(loginData)\n",
    "trainTradeData=tradeDataInit(tradeData)\n",
    "X_train,y_train=allDataInit(trainLoginData,trainTradeData)\n",
    "# train_sizes参数指定用于生成学习曲线的训练集数量，如果是分数指的是相对数量，整数指的是绝对数量\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr, X=X_train, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10), cv=3,\n",
    "                                                        n_jobs=2,scoring=rocJdScore)\n",
    "print('==='*10)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.savefig(\"curve.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
