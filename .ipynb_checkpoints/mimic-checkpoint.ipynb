{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#log_id,id转换为字符串\n",
    "loginData=pd.read_csv(\"t_login.csv\",dtype={'log_id':str,'id':str})\n",
    "loginTestData=pd.read_csv(\"t_login_test.csv\",dtype={'log_id':str,'id':str})\n",
    "tradeData=pd.read_csv(\"trade_2_login.csv\",dtype={'id':str,'login_id':str})\n",
    "tradeTestData=pd.read_csv(\"t_trade_test_2_login.csv\",dtype={'id':str,'login_id':str})\n",
    "loginTestData=loginTestData.append(loginData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到DataFrame中的无重复的id\n",
    "def getUserIDFromDataFrame(dataFrame):\n",
    "    return pd.DataFrame({'id':dataFrame['id'].unique()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到登录中所用时间为整秒的计算\n",
    "def getTimelongScale(loginData,test):\n",
    "    #计算是否为整秒\n",
    "    loginData['timeScale']=(loginData['timelong']%1000==0)\n",
    "    #分别为整数 ，不为整数的次数\n",
    "    gd=loginData['timeScale'].groupby([loginData['id'],loginData['timeScale']])\n",
    "    tmp=gd.count().unstack().reset_index()\n",
    "    tmp=tmp.fillna(0)\n",
    "    test=pd.merge(tmp,test,on='id',how='inner')\n",
    "#     print(test.head(2))\n",
    "    del loginData['timeScale'],tmp\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#得到某列的分组不同的个数\n",
    "def getCountsByColumnName(loginData,test,columnName):\n",
    "    num=loginData[['id',columnName]].groupby(loginData['id'])[columnName].nunique()\n",
    "    t=pd.DataFrame(num)\n",
    "    t.insert(0, 'id', num.index)\n",
    "    t.columns=['id',columnName+'_Counts']\n",
    "    test=pd.merge(t,test,on='id',how='inner')\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到某列的分组平均值\n",
    "def getMeanByColumnName(loginData,test,columnName):\n",
    "    t=loginData[columnName].groupby(loginData['id'])\n",
    "    t=t.mean().reset_index()\n",
    "    t.columns=['id',columnName+'_Mean']\n",
    "    test=pd.merge(t,test,on='id',how='inner')\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#得到某列的分组最小值\n",
    "def getMinByColumnName(loginData,test,columnName):\n",
    "    t=loginData[columnName].groupby(loginData['id'])\n",
    "    t=t.min().reset_index()\n",
    "    t.columns=['id',columnName+'_min']\n",
    "    test=pd.merge(t,test,on='id',how='inner')\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到某列的分组最大值\n",
    "def getMaxByColumnName(loginData,test,columnName):\n",
    "    t=loginData[columnName].groupby(loginData['id'])\n",
    "    t=t.max().reset_index()\n",
    "    t.columns=['id',columnName+'_max']\n",
    "    test=pd.merge(t,test,on='id',how='inner')\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#得到某列的分组方差\n",
    "def getVarByColumnName(loginData,test,columnName):\n",
    "    t=loginData[columnName].groupby(loginData['id'])\n",
    "    t=t.var().reset_index()\n",
    "    t.columns=['id',columnName+'_var']\n",
    "    test=pd.merge(t,test,on='id',how='inner')\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#得到某列的分组标准差\n",
    "def getStdByColumnName(loginData,test,columnName):\n",
    "    t=loginData[columnName].groupby(loginData['id'])\n",
    "    t=t.std().reset_index()\n",
    "    t.columns=['id',columnName+'_std']\n",
    "    test=pd.merge(t,test,on='id',how='inner')\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#得到对登录result的处理\n",
    "def getLoginResultCount(loginData,test):\n",
    "    r31=loginData[loginData['result']!=1]\n",
    "    t=r31['result'].groupby(r31['id'])\n",
    "    t=t.count().reset_index()\n",
    "    t.columns=['id','result_no1_Counts']\n",
    "    test=pd.merge(t,test,on='id',how='inner')\n",
    "    test=test.fillna(0)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tradeDataInit中 \n",
    "``` tradeData['trade_time_sub'] = tradeData[['id','tx']].sort_values(by='tx').groupby('id').diff()['tx']```\n",
    "可以datetime类型的数据，不能用str类型的（time_x）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#处理交易数据\n",
    "def tradeDataInit(tradeData,loginData):\n",
    "    tradeData=tradeData.copy()\n",
    "    #构建一个小时的\n",
    "    tradeData['hours']=tradeData['time'].str.extract('\\\\s(\\\\d\\\\d):')\n",
    "    tradeData['hours']=tradeData['hours'].astype('int')\n",
    "    tradeData=pd.merge(tradeData,loginData[['log_id','time']],left_on='login_id',right_on='log_id',how='inner')\n",
    "    del tradeData['log_id']\n",
    "    #交易时间\n",
    "    tradeData['tx']=pd.to_datetime(tradeData['time_x'])\n",
    "    #登录时间\n",
    "    tradeData['ty']=pd.to_datetime(tradeData['time_y'])\n",
    "    #交易时间和登录时间之间的差值\n",
    "    tradeData['st']=(tradeData['tx']-tradeData['ty']).dt.seconds\n",
    "    #每次交易时间的差\n",
    "    tradeData['trade_time_sub'] = tradeData[['id','tx']].sort_values(by='tx').groupby('id').diff()['tx']\n",
    "    \n",
    "    tradeData['trade_time_sub_day']=tradeData['trade_time_sub'].dt.days\n",
    "    tradeData=getMaxByColumnName(tradeData,tradeData,'trade_time_sub_day')\n",
    "    tradeData=getMeanByColumnName(tradeData,tradeData,'trade_time_sub_day')\n",
    "    tradeData=getMinByColumnName(tradeData,tradeData,'trade_time_sub_day')\n",
    "    tradeData=getStdByColumnName(tradeData,tradeData,'trade_time_sub_day')\n",
    "    tradeData=getVarByColumnName(tradeData,tradeData,'trade_time_sub_day')\n",
    "    #使用的比例\n",
    "    tradeData=getTradeLoginColumScale(tradeData,loginData,'device')\n",
    "    tradeData=getTradeLoginColumScale(tradeData,loginData,'city')\n",
    "    \n",
    "    del tradeData['tx'],tradeData['ty'],tradeData['time_y'],tradeData['login_id'],tradeData['trade_time_sub']\n",
    "    tradeData.rename(columns={'time_x':'time'},inplace=True)\n",
    "    return tradeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getTradeLoginColumScale(tradeData,loginData,cname):\n",
    "    #计算cname列上分别使用的个数\n",
    "    c_count=loginData[['id',cname,'log_id']].groupby(['id',cname]).count()\n",
    "    c_count=c_count.reset_index()\n",
    "    c_count.columns=['id',cname,cname+'_count_tmp']\n",
    "    #使用的总个数\n",
    "    c_sum=c_count[['id',cname+'_count_tmp']].groupby('id').sum().reset_index()\n",
    "    c_sum.columns=['id',cname+'_count_sum']\n",
    "    c=pd.merge(c_count,c_sum,on='id',how='inner')\n",
    "    #使用的比例\n",
    "    c[cname+'_scale']=c[cname+'_count_tmp']/c[cname+'_count_sum']\n",
    "    del c[cname+'_count_tmp'],c[cname+'_count_sum']\n",
    "    c=pd.merge(loginData[['log_id','id',cname]],c,on=['id',cname],how='inner')\n",
    "    tradeData=pd.merge(tradeData,c[['log_id',cname+'_scale']],left_on='login_id',right_on='log_id',how='inner')\n",
    "    del c,tradeData['log_id']\n",
    "    return tradeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#把处理后的登录数据和交易数据内连接\n",
    "def createAllData(test,tradeData):\n",
    "    tmp=pd.merge(test,tradeData,on='id',how='inner')\n",
    "#     tmp=tmp.fillna(0)\n",
    "#     print(tmp.info())\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "#评估函数\n",
    "def rocJdScore(*args):\n",
    "    from sklearn import metrics\n",
    "    return metrics.make_scorer(fbeta_score,beta=0.1, greater_is_better=True)(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成训练用的pipline\n",
    "def getPipe():\n",
    "    # 下面，我要用逻辑回归拟合模型，并用标准化和PCA（30维->2维）对数据预处理，用Pipeline类把这些过程链接在一起\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    import xgboost as xgb\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "    #xgb的配置\n",
    "    xgbFier = XGBClassifier(\n",
    "             learning_rate =0.3,\n",
    "             n_estimators=1000,\n",
    "             max_depth=5,\n",
    "             min_child_weight=1,\n",
    "             gamma=0,\n",
    "             subsample=0.8,\n",
    "             colsample_bytree=0.8,\n",
    "             objective= 'binary:logistic',\n",
    "             nthread=2,\n",
    "             scale_pos_weight=1,\n",
    "             seed=27,\n",
    "             silent=0\n",
    "    )\n",
    "    # 用StandardScaler和PCA作为转换器，LogisticRegression作为评估器\n",
    "    estimators = [\n",
    "#         ('scl', StandardScaler()), \n",
    "#                   ('pca', PCA(n_components=2)), \n",
    "#                    ('rf', RandomForestClassifier(random_state=1,\n",
    "#                                                  max_depth= 50,\n",
    "#                                                  min_samples_leaf= 3,\n",
    "#                                                  min_samples_split= 10,\n",
    "#                                                  n_estimators= 20,\n",
    "#                                                 )),\n",
    "#                   ('dtc',DecisionTreeClassifier(criterion='entropy')),\n",
    "                                    ('xgb',xgbFier),\n",
    "#                   ('lr', LogisticRegression())\n",
    "                 ]\n",
    "    # estimators = [ ('clf', RandomForestClassifier(random_state=1))]\n",
    "    # Pipeline类接收一个包含元组的列表作为参数，每个元组的第一个值为任意的字符串标识符，\n",
    "    #比如：我们可以通过pipe_lr.named_steps['pca']来访问PCA组件;第二个值为scikit-learn的转换器或评估器\n",
    "    pipe_lr = Pipeline(estimators)\n",
    "    return pipe_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到训练用的测试集元组（x，y）\n",
    "def getTrainData(isUndersample=False):\n",
    "    allData=transferData(loginData,tradeData)\n",
    "    if(isUndersample):\n",
    "        #进行undersample的处理\n",
    "        number_records_fraud=len(allData[allData['is_risk']==1]) #有风险的个数\n",
    "        fraud_indices=np.array(allData[allData['is_risk']==1].index) #有风险的index\n",
    "        normal_indices=allData[allData['is_risk']==0].index\n",
    "        random_normal_indices=np.random.choice(normal_indices,number_records_fraud,replace=False)\n",
    "        random_normal_indices=np.array(random_normal_indices)\n",
    "        under_sample_indices=np.concatenate([fraud_indices,random_normal_indices])\n",
    "        allData=allData.iloc[under_sample_indices,:]\n",
    "    \n",
    "    x=allData.iloc[:,3:].values\n",
    "    y=allData['is_risk'].values\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#生成学习算法\n",
    "def jdPipeFited(pipe_lr):    \n",
    "    x,y=getTrainData(isUndersample=False)\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    # 拆分成训练集(80%)和测试集(20%)\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1) \n",
    "    \n",
    "    pipe_lr.fit(x, y)\n",
    "    return pipe_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "你可以理解为短时间内变化城市、切换IP、更换设备、三更半夜多笔交易、不在常用设备登陆、不在常在城市登陆、短时间多次登陆的后续交易\n",
    "'''\n",
    "#生成训练数据\n",
    "def transferData(loginData,tradeData):  \n",
    "    print 'loginData: ',loginData.shape\n",
    "    lData=getUserIDFromDataFrame(loginData)\n",
    "    #登录耗费时间段是否为整数\n",
    "    print 'lData.shape: ', lData.shape\n",
    "    lData=getTimelongScale(loginData,lData)\n",
    "    print 'lData.shape: ', lData.shape\n",
    "    lData=getMinByColumnName(loginData,lData,'timelong')\n",
    "    print 'lData.shape: ', lData.shape\n",
    "    lData=getMaxByColumnName(loginData,lData,'timelong')\n",
    "    print 'lData.shape: ', lData.shape\n",
    "    lData=getMeanByColumnName(loginData,lData,'timelong')\n",
    "    print 'lData.shape: ', lData.shape\n",
    "    lData=getVarByColumnName(loginData,lData,'timelong')\n",
    "    print 'lData.shape: ', lData.shape\n",
    "    lData=getStdByColumnName(loginData,lData,'timelong')\n",
    "    print 'lData.shape: ', lData.shape\n",
    "# #     #device的个数\n",
    "    lData=getCountsByColumnName(loginData,lData,'device')\n",
    "    print 'lData.shape: ', lData.shape\n",
    "# #     #ip的个数\n",
    "    lData=getCountsByColumnName(loginData,lData,'ip')\n",
    "    print 'lData.shape: ', lData.shape\n",
    "    lData=getCountsByColumnName(loginData,lData,'log_from')\n",
    "    print 'lData.shape: ', lData.shape\n",
    "    \n",
    "    lData=getCountsByColumnName(loginData,lData,'type')\n",
    "    print 'lData.shape: ', lData.shape\n",
    "#     #城市的个数\n",
    "    lData=getCountsByColumnName(loginData,lData,'city')\n",
    "    print 'lData.shape: ', lData.shape\n",
    "    #登录的次数\n",
    "    lData=getCountsByColumnName(loginData,lData,'log_id')\n",
    "    print 'lData.shape: ', lData.shape\n",
    "    #平均值\n",
    "#     lData=getMeanByColumnName(loginData,lData,'device')\n",
    "#     lData=getMeanByColumnName(loginData,lData,'log_from')\n",
    "#     lData=getMeanByColumnName(loginData,lData,'ip')\n",
    "#     lData=getMeanByColumnName(loginData,lData,'city')\n",
    "#     lData=getMeanByColumnName(loginData,lData,'result')\n",
    "#     lData=getMeanByColumnName(loginData,lData,'type')\n",
    "    #result的处理\n",
    "    lData=getLoginResultCount(loginData,lData)\n",
    "    print 'lData.shape: ', lData.shape\n",
    "    tData=tradeData.copy()\n",
    "    print 'lData.shape: ', lData.shape\n",
    "    #lData.to_csv('lData.csv')\n",
    "    #tData.to_csv('tData.csv')\n",
    "    #loginData.to_csv('loginData.csv')\n",
    "    tData=tradeDataInit(tData,loginData)\n",
    "#     tData=getLastSubTime(loginData,tData)\n",
    "    allData=createAllData(lData,tData)\n",
    "    del allData['time']\n",
    "    # get a list of columns\n",
    "    cols = list(allData)\n",
    "    if 'is_risk' in allData.columns:\n",
    "        cols.insert(0, cols.pop(cols.index('is_risk')))\n",
    "    cols.insert(0, cols.pop(cols.index('rowkey')))\n",
    "    \n",
    "    allData = allData.ix[:, cols]\n",
    "    print(allData.head(2))\n",
    "    return allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#k-fold交叉验证\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "pipe_lr=getPipe()\n",
    "X_train,y_train=getTrainData(isUndersample=False)\n",
    "\n",
    "#记录程序运行时间\n",
    "import time \n",
    "start_time = time.time()\n",
    "scores = cross_val_score(estimator=pipe_lr, X=X_train, y=y_train, cv=10, n_jobs=2,scoring=rocJdScore)\n",
    "print('score-----: 'scores)\n",
    "#整体预测\n",
    "X_train,y_train=getTrainData(isUndersample=False)\n",
    "print('X_train--------------')\n",
    "pipe_lr\n",
    "#输出运行时长\n",
    "cost_time = time.time()-start_time\n",
    "print(\"交叉验证 success!\",'\\n',\"cost time:\",cost_time,\"(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网格搜索实验\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "parameters = {\n",
    "#     'rf__n_estimators': (5, 10, 20, 50),\n",
    "#     'rf__max_depth': (50, 150, 250),\n",
    "#     'rf__min_samples_split': [10, 2, 3],\n",
    "#     'rf__min_samples_leaf': (1, 2, 3),\n",
    "    #xgb的参数\n",
    "    'xgb__max_depth':(4,6),\n",
    "    'xgb__learning_rate':(0.3,0.5)\n",
    "\n",
    "}\n",
    "pipe_lr=getPipe()\n",
    "X_train,y_train=getTrainData()\n",
    "\n",
    "\n",
    "#网格搜索\n",
    "grid_search = GridSearchCV(pipe_lr, parameters, n_jobs=-1, verbose=1, scoring=rocJdScore)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#获取最优参数\n",
    "print('最佳效果：%0.3f' % grid_search.best_score_)\n",
    "print('最优参数：')\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print('\\t%s= %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# #预测以及分类器参数报告\n",
    "# predictions = grid_search.predict(X_test)\n",
    "# print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#学习曲线\n",
    "from sklearn.learning_curve import learning_curve\n",
    "\n",
    "pipe_lr = getPipe()\n",
    "X_train,y_train=getTrainData()\n",
    "# train_sizes参数指定用于生成学习曲线的训练集数量，如果是分数指的是相对数量，整数指的是绝对数量\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr, X=X_train, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10), cv=10,\n",
    "                                                        n_jobs=2,scoring=rocJdScore)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#预测\n",
    "pipe=getPipe()\n",
    "pipe=jdPipeFited(pipe)\n",
    "preData=transferData(loginTestData,tradeTestData)\n",
    "x_pred=preData.iloc[:,2:].values\n",
    "y_pred=pipe.predict(x_pred)\n",
    "np.sum(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-c251ad943152>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msubData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rowkey'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msubData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'is_risk'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#之前用很多inner join，很多数据没有，都默认处理为没有风险\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msubData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtradeTestData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rowkey'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rowkey'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "p=pd.DataFrame(y_pred)\n",
    "subData=pd.DataFrame(preData['rowkey'])\n",
    "subData['is_risk']=p\n",
    "#之前用很多inner join，很多数据没有，都默认处理为没有风险\n",
    "subData=pd.merge(tradeTestData[['rowkey']],subData,on='rowkey',how='left')\n",
    "subData=subData.fillna(0)\n",
    "subData['is_risk']=subData['is_risk'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-9588d031587f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msubData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./sub.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'subData' is not defined"
     ]
    }
   ],
   "source": [
    "subData.to_csv('./sub.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                       | 0/132719 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-bebcaa546333>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtData\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mttt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetLastSubTime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloginData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtradeData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"over\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-163-bebcaa546333>\u001b[0m in \u001b[0;36mgetLastSubTime\u001b[1;34m(loginData, tradeData)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtradeTime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrade\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mtradeTime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtradeTime\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mlogin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloginData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloginData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloginData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mtradeTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mloginMaxIdx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\ops.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\numpy\\core\\numeric.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, *exc_info)\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3070\u001b[1;33m         \u001b[0mseterr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moldstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3071\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_Unspecified\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3072\u001b[0m             \u001b[0mseterrcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moldcall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\numpy\\core\\numeric.pyc\u001b[0m in \u001b[0;36mseterr\u001b[1;34m(all, divide, over, under, invalid)\u001b[0m\n\u001b[0;32m   2757\u001b[0m     maskvalue = ((_errdict[divide] << SHIFT_DIVIDEBYZERO) +\n\u001b[0;32m   2758\u001b[0m                  \u001b[1;33m(\u001b[0m\u001b[0m_errdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mover\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<<\u001b[0m \u001b[0mSHIFT_OVERFLOW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2759\u001b[1;33m                  \u001b[1;33m(\u001b[0m\u001b[0m_errdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munder\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<<\u001b[0m \u001b[0mSHIFT_UNDERFLOW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2760\u001b[0m                  (_errdict[invalid] << SHIFT_INVALID))\n\u001b[0;32m   2761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#对购物到相近登录的时间间隔\n",
    "from  datetime import datetime\n",
    "from tqdm import tqdm\n",
    "def getLastSubTime(loginData,tradeData):    \n",
    "    tData=tradeData.copy()\n",
    "    subTime=[]\n",
    "    dateFormatStr='%Y-%m-%d %H:%M:%S'\n",
    "    pbar = tqdm(total=len(tData.index)) \n",
    "    for x in tData.index:\n",
    "        trade=tData.loc[x]\n",
    "        id=trade['id']\n",
    "        #pbar.update(1)\n",
    "        tradeTime=trade['time']\n",
    "        tradeTime=tradeTime[0:19]\n",
    "        login=loginData[(loginData['id']==id)&(loginData['time']<tradeTime)]\n",
    "        if(len(login)>0):\n",
    "            loginMaxIdx=login.timestamp.idxmax()\n",
    "            loginMax=loginData.iloc[loginMaxIdx]\n",
    "            lTime= datetime.strptime(loginMax['time'],dateFormatStr)\n",
    "            tTime=datetime.strptime(tradeTime,dateFormatStr)\n",
    "            sub=(tTime-lTime).seconds\n",
    "            subTime.append(loginMax['log_id'])\n",
    "            print('rowkey='+str(trade['rowkey'])+'log_id'+str(login['log_id'].values[0]))\n",
    "        else:\n",
    "            subTime.append(None)\n",
    "    tData['login_id']=subTime\n",
    "    pbar.close() \n",
    "    return tData\n",
    "ttt=getLastSubTime(loginData,tradeData)\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dftime3:------------\n",
      "    C  id                  tx  trade_time_sub\n",
      "0   0   4 2017-09-10 11:12:23             NaN\n",
      "1  12   2 2017-10-22 01:31:53            23.0\n",
      "2   9   4 2017-09-18 13:24:34             8.0\n",
      "3  13   2 2017-09-28 12:44:54             4.0\n",
      "4  12   2 2017-09-24 08:19:38             NaN\n",
      "\n",
      "processed dftime3-------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>id</th>\n",
       "      <th>tx</th>\n",
       "      <th>trade_time_sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-09-10 11:12:23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-10-22 01:31:53</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-09-18 13:24:34</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-09-28 12:44:54</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-09-24 08:19:38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C  id                  tx  trade_time_sub\n",
       "0   0   4 2017-09-10 11:12:23             NaN\n",
       "1  12   2 2017-10-22 01:31:53            23.0\n",
       "2   9   4 2017-09-18 13:24:34             8.0\n",
       "3  13   2 2017-09-28 12:44:54             4.0\n",
       "4  12   2 2017-09-24 08:19:38             NaN"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'dftime3:------------\\n',dftime3\n",
    "dftime3['trade_time_sub'] = dftime3.sort_values(by='tx').groupby('id').diff()['tx'].dt.days\n",
    "print '\\nprocessed dftime3-------- '\n",
    "dftime3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx type <class 'pandas._libs.tslib.Timestamp'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "diff() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-464-a852a1da8e22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdftime22\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tx'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdftime22\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'tx type'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdftime22\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdftime22\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trade_time_sub'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdftime22\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdftime22\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36mdiff\u001b[1;34m(self, periods, axis)\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m                         return self._aggregate_item_by_item(name,\n\u001b[1;32m--> 612\u001b[1;33m                                                             *args, **kwargs)\n\u001b[0m\u001b[0;32m    613\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36m_aggregate_item_by_item\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3554\u001b[0m             \u001b[1;31m# GH6337\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3555\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_columns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3556\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3558\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: diff() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "C = pd.DataFrame({'C':[0,12,9,13,5]})\n",
    "dftime22 = pd.read_csv('tx.csv').head(5)#[['id','tx']].head(5)\n",
    "dftime22 = pd.concat([C,dftime22],axis=1)\n",
    "dftime22['tx'] = pd.to_datetime(dftime22['tx'])\n",
    "print 'tx type',type(dftime22['tx'][0])\n",
    "dftime22['trade_time_sub'] = dftime22.sort_values(by='tx').groupby('id').diff()['tx'].dt.seconds\n",
    "dftime22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "diff() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-411-56c8ad59ad74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdftime222\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trade_time_sub'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdftime222\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36mdiff\u001b[1;34m(self, periods, axis)\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m                         return self._aggregate_item_by_item(name,\n\u001b[1;32m--> 612\u001b[1;33m                                                             *args, **kwargs)\n\u001b[0m\u001b[0;32m    613\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pandas\\core\\groupby.pyc\u001b[0m in \u001b[0;36m_aggregate_item_by_item\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3554\u001b[0m             \u001b[1;31m# GH6337\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3555\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_columns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3556\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3558\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: diff() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "dftime222['trade_time_sub'] = dftime222[['tx','id']].sort_values(by='tx').groupby('id').diff()['tx'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeFormat = '%Y-%m-%d %H:%M:%S'\n",
    "time1 = datetime.strptime('2017-9-10 11:12:23',timeFormat)\n",
    "time2 = datetime.strptime('2017-10-22 1:31:53',timeFormat)\n",
    "time3 = datetime.strptime('2017-9-18 13:24:34',timeFormat)\n",
    "time4 = datetime.strptime('2017-9-28 12:44:54',timeFormat)\n",
    "time5 = datetime.strptime('2017-9-24 8:19:38',timeFormat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>id</th>\n",
       "      <th>tx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-09-10 11:12:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-10-22 01:31:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-09-18 13:24:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-09-28 12:44:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-09-24 08:19:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C  id                  tx\n",
       "0   0   4 2017-09-10 11:12:23\n",
       "1  12   2 2017-10-22 01:31:53\n",
       "2   9   4 2017-09-18 13:24:34\n",
       "3  13   2 2017-09-28 12:44:54\n",
       "4  12   2 2017-09-24 08:19:38"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftime3 = pd.DataFrame({'tx':[time1,time2,time3,time4,time5],'id':[4,2,4,2,2],'C':[0,12,9,13,12]})\n",
    "dftime3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslib.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "print type(dftime3['tx'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>id</th>\n",
       "      <th>tx</th>\n",
       "      <th>trade_time_sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-09-10 11:12:23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-10-22 01:31:53</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-09-18 13:24:34</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-09-28 12:44:54</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-09-24 08:19:38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C  id                  tx  trade_time_sub\n",
       "0   0   4 2017-09-10 11:12:23             NaN\n",
       "1  12   2 2017-10-22 01:31:53            23.0\n",
       "2   9   4 2017-09-18 13:24:34             8.0\n",
       "3  13   2 2017-09-28 12:44:54             4.0\n",
       "4  12   2 2017-09-24 08:19:38             NaN"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftime3['trade_time_sub'] = dftime3.sort_values(by='tx').groupby('id').diff()['tx'].dt.days\n",
    "dftime3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id  tim2                  tx\n",
      "0  A     0 2017-09-10 11:12:23\n",
      "1  B    12 2017-10-22 01:31:53\n",
      "2  A     9 2017-09-18 13:24:34\n",
      "3  B    13 2017-09-28 12:44:54\n",
      "4  A    34 2017-09-24 08:19:38\n",
      "  id  tim2                  tx\n",
      "0  A     0 2017-09-10 11:12:23\n",
      "2  A     9 2017-09-18 13:24:34\n",
      "4  A    34 2017-09-24 08:19:38\n",
      "3  B    13 2017-09-28 12:44:54\n",
      "1  B    12 2017-10-22 01:31:53\n",
      "diff:\n",
      "   tim2               tx\n",
      "0   NaN              NaT\n",
      "2   9.0  8 days 02:12:11\n",
      "4  25.0  5 days 18:55:04\n",
      "3   NaN              NaT\n",
      "1  -1.0 23 days 12:46:59\n",
      "------------\n",
      "0                NaT\n",
      "2    8 days 02:12:11\n",
      "4    5 days 18:55:04\n",
      "3                NaT\n",
      "1   23 days 12:46:59\n",
      "Name: tx, dtype: timedelta64[ns]\n",
      "------------\n",
      "  id  tim2                  tx  trade_time_sub\n",
      "0  A     0 2017-09-10 11:12:23             NaN\n",
      "1  B    12 2017-10-22 01:31:53            23.0\n",
      "2  A     9 2017-09-18 13:24:34             8.0\n",
      "3  B    13 2017-09-28 12:44:54             NaN\n",
      "4  A    34 2017-09-24 08:19:38             5.0\n"
     ]
    }
   ],
   "source": [
    "dftime2 = pd.DataFrame({'tx':[time1,time2,time3,time4,time5],'id':['A','B','A','B','A'],'tim2':[0,12,9,13,34]})\n",
    "print dftime2\n",
    "print dftime2.sort_values(by='tx')\n",
    "print 'diff:'\n",
    "print dftime2.sort_values(by='tx').groupby('id').diff()\n",
    "print '------------'\n",
    "print dftime2.sort_values(by='tx').groupby('id').diff()['tx']\n",
    "print '------------'\n",
    "dftime2['trade_time_sub'] = dftime2.sort_values(by='tx').groupby('id').diff()['tx'].dt.days\n",
    "print dftime2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
